<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Algorithms on pinkhello</title><link>https://pinkhello.cc/tags/algorithms/</link><description>Recent content in Algorithms on pinkhello</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>pinkhello</copyright><lastBuildDate>Sat, 05 Mar 2022 22:05:23 +0800</lastBuildDate><atom:link href="https://pinkhello.cc/tags/algorithms/index.xml" rel="self" type="application/rss+xml"/><item><title>细谈线程池设计与监控</title><link>https://pinkhello.cc/posts/47-%E7%BB%86%E8%B0%88%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AE%BE%E8%AE%A1%E4%B8%8E%E7%9B%91%E6%8E%A7/</link><pubDate>Sat, 05 Mar 2022 22:05:23 +0800</pubDate><guid>https://pinkhello.cc/posts/47-%E7%BB%86%E8%B0%88%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AE%BE%E8%AE%A1%E4%B8%8E%E7%9B%91%E6%8E%A7/</guid><description>前言 万年八股文，在工作中肯定多多少少都使用了线程池，但有没有真正的去了解线程池的整个运行机制和核心关键点。今天分享一下。
线程池简介 先说 线程(Thread) , 在 Wiki 的解释是操作系统能进行运算调度的最小单元。包含在进程中，是进程实际运作的单元。 OK，先记住这一点，我们说 线程池(Thread Pool) ，顾名思义，基于池化思想的管理线程的手段（工具）。既然叫线程池了，可以 知道肯定是多线程的服务环境下。
我们都知道Server的资源是有限的，不可能无止境的扩张（从成本、运维上考虑）。线程过分的开辟的话，会导致整体服务器资源吃紧（线程带来的开销、创建、调度等等）。 池化的思想，线程池维护着多个线程，等待调度分配并发任务去执行。一方面避免有任务就创建线程带来的额外的开销，另一方面也是保护服务器产生过多的线程数量。
线程池解决什么问题 线程池解决的核心问题是资源管理问题，在并发环境下，系统和服务并不知道在什么时候需要多少资源。而 池化(Pooling) 思想，就是为了将资源统一管理的情况下，减小风险的思想。
Wiki上 ThreadPool图
P.S : 池化思想举例
内存池(Memory Pool) 对象池(Object Pool) 即实例池 连接池(Connection Pool) 线程池核心设计 在看线程池的设计之前，先了解一下线程池的构造参数
corePoolSize – the number of threads to keep in the pool, even if they are idle, unless allowCoreThreadTimeOut is set maximumPoolSize – the maximum number of threads to allow in the pool keepAliveTime – when the number of threads is greater than the core, this is the maximum time that excess idle threads will wait for new tasks before terminating.</description></item><item><title>LRUCache 的实现</title><link>https://pinkhello.cc/posts/46-lrucache-%E5%AE%9E%E7%8E%B0/</link><pubDate>Thu, 10 Feb 2022 18:59:50 +0800</pubDate><guid>https://pinkhello.cc/posts/46-lrucache-%E5%AE%9E%E7%8E%B0/</guid><description>文引 要实现 LRU Cache，我们需要了解 LRU Cache 的运行原理。
LRU Cache LRU (Least Recently Used) Cache 是一种缓存淘汰算法，最少最近使用的Cache。也就是说，在淘汰的时候，淘汰的是最长时间未使用（或者使用最少）的数据
如下图，容量是为 3 的缓存:
一开始，Cache 为空,添加一个 12 元素进入，后面依次放入了 11 和 10。这时候将缓存填满了。 将放入 9 的时候，因为缓存满了，需要移除最长时间未使用的数据。所以 12 被移除，9 被加入。 P.S.: 这边未考虑使用操作，其实也可以想像的到，如果要是使用了，就将使用的元素从缓存移除，重新加入到缓存中
经过上述了解，已经直到了 LRU 的运行机制，这样我们总结特点：
Cache 大小固定有限 Cache Full 后，后续操作都需要执行 LRU 操作 Cache 操作支持并发 Cache 的 添加、排序、获取 尽量都是 O(1) 操作 Structure of LRU Cache 要考虑设计 LRU Cache，我们需要根据其特点来设计：
特性1: LRU Cache 是一个 Queue，如果 Queue 里面的某个元素被访问了，它应该被迁移到淘汰的末位。 特性2:LRU Cache 要有固定容量（内存有限）, 当新加一个元素的时候，是添加到 Queue Head；当发送淘汰的时候，淘汰的是 Queue Tail。（FIFO） 特性3: 查找命中缓存的数据，必须在 最少的固定的时间内 完成。也就是我们我们必须尽量保证时间复杂度 O(1) 特性4: 移除最近最少使用的元素，也必须在 最少的固定的时间内 完成。同上 O(1) 要满足 特性1 和 特性2 还是很简单的,要实现一个 Queue 我们可以使用数据结构 固定大小的Linked List 或 固定大小的Array List 做实现。 但是在兼顾 特性3 的时候，可以想象到要尽量 添加、命中 都是 O(1) 操作，在 Queue 中基本不可能。但是我们可以预判到 HashMap 可以最大化的解决这个问题， 因为HashMap最理想的情况下达到 命中缓存为 O(1) 操作，到此，我们发现 LRU Cache 的设计应该是 HashMap + List； 下面再去考虑 特性4，在 Cache 满的情况下，考虑每次添加新的元素都要执行LRU策略，这时候可预见的对于这个 List的插入``删除比查询多， 肯定选择是 Linked List，且是 DoublyLinkedList 不是 SingleLinkedList (出于操作O(1)考虑)</description></item><item><title>如何去实现RingBuffer</title><link>https://pinkhello.cc/posts/45-%E5%A6%82%E4%BD%95%E5%8E%BB%E5%AE%9E%E7%8E%B0ringbuffer/</link><pubDate>Thu, 10 Feb 2022 14:39:59 +0800</pubDate><guid>https://pinkhello.cc/posts/45-%E5%A6%82%E4%BD%95%E5%8E%BB%E5%AE%9E%E7%8E%B0ringbuffer/</guid><description>文引 RingBuffer, 名如其意: 环形缓存区/环形队列，不同于一般的队列，特征是首尾相接。
RingBuffer 如何工作的 RingBuffer 是一个有界的循环的数据结构，主要用于多线程下进行的数据缓存。在持续的写入数据的时候，到达末尾的时候链接到头，效果上达成一个环状。
实现它的方式 它是有界的数组实现，如图。
而且我们还要关注到 reader指针 、 writer指针、 头尾相连
reader pointer 下一个可读元素 writer pointer 下一个可插入的元素 slot 数组头 和 数组尾 相互链接 讨论 ringbuffer 的运行方式 ringbuffer 的关键参数, read seq &amp;amp; write seq
reader pointer seq =&amp;gt; 从 0 开始，随着读取消耗一个元素 +1 writer pointer seq =&amp;gt; 从 -1 开始，插入一个元素时候 +1 可以看出两种 Seq 对 容量进行 Mod 操作可以将 seq 映射到 ringbuffer 的 index 上.
array_index = seq % capacity 基于上面的思想，我们看 ringbuffer 的核心操作</description></item><item><title>短链接的思考与技术实现</title><link>https://pinkhello.cc/posts/35-%E7%9F%AD%E9%93%BE%E6%8E%A5%E7%9A%84%E6%80%9D%E8%80%83%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/</link><pubDate>Sun, 05 Sep 2021 00:19:13 +0800</pubDate><guid>https://pinkhello.cc/posts/35-%E7%9F%AD%E9%93%BE%E6%8E%A5%E7%9A%84%E6%80%9D%E8%80%83%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/</guid><description>前提 又到了一月一度的清理消息的时候了,开始清理短信,忽然见到一个幸福里的通知短信，那是在短信到达之前，本🐶打肿脸充胖子在幸福里小程序里面咨询上海的一套二手房的价格的，后来没关注， 这个短链接 https://m.xflapp.com/s/vdwecR 引起了本🐶的兴趣.
我发问：如何去实现一个短链接服务?
短链接的原理 短链接的核心是什么?
构建的短链接和长链接(我们真实的访问地址)的唯一关联映射、也就是映射标识生成算法。
从这个定义也能得到短链接服务的几个特点:
1⃣️具有高性能 2⃣️是排列组合数量量要足够大 3⃣️要具有不易破解、且破解难度极大 拆解短链接 👆的短链接 https://m.xflapp.com/s/vdwecR 我掏出了我的神器 Chrome 打开了一下，直接跳转到了http://m.haoduofangs.com/f100/activity/client/tt_im?app_id=13&amp;amp;customer_user_id=62800686641&amp;amp;realtor_id=3781951248937422. 好了仔细看一下请求和响应,响应的302,响应头中带了需要跳转的地址.
综上我示意图:
可以看出来,构建唯一映射关系是将原有的固定长链接生成一个或多个短链接,1:N关系。生成的短链接必须满足:
不能轻易的被猜出来(破解),被恶意遍历。 [一定时间内]不能重复(一个短链接在一定时间内只能对应一个长链接、这个一定时间可以是永久) 长度尽量短 在短信运营商会限制短信的长度、如果太长、留给运营人员或者客户的的字符长度会有🚫，这不是给同事或客户挖坑么。 链接变二维码，二维码的点位会非常密集，不利于客户端识别和传输 长度太长，从个人情感里面也比较繁琐这样的长链接，不易记录和输入 回到这个唯一映射关系上来，就是需要对这个长链接做 Hash，和大多数哈希算法一致,生成算法需要就是要具备唯一性和较低的碰撞率的特点,而在短链接场景下，又决定了它还要具备短线精悍并且易于传输的特点。
短链接压缩生成算法特点:
短小精悍、易于传输 高度唯一性 低碰撞率 短链接生成算法 从上图可以看出，协议、域名均为不可变部分，能定制的只有压缩码(哈希码), 那么作为程序🐶能玩的也只有这部分了。
回到幸福里通知短信的短链接, 它抛掉协议和域名两部分,还剩下s/vdwecR, 可以看出Path其实是两层,第一层是s,第二层是vdwecR， 可以抽象为{pathLevel1}/{pathLevel2},{pathLevel1}为了简短使用了单个字母(可以区分大小写)或者数字, {pathLevel2} 为了满足低碰撞率和唯一性，使用了6位区分大小写字母和数字的组合体。 那么像这个组合体的最大组合数量是多少呢？{pathLevel1} 假设只有一位, {pathLevel2} 有6位,从当前的例子来看，不考虑取值为数字的可能，那么它的组合数 每个取值都是(26个大写字母 + 26个小写字母) ，也就是 52 ^ 7 = 1,028,071,702,528 ,已达万亿级别数量级。</description></item><item><title>一致性哈希算法</title><link>https://pinkhello.cc/posts/01-%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</link><pubDate>Sun, 10 Feb 2019 10:00:00 +0800</pubDate><guid>https://pinkhello.cc/posts/01-%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</guid><description>分布式均衡寻址算法 在分布式集群中，对机器的添加删除，或者机器故障后自动脱落集群的操作是分布式集群管理的基本功能。
在集群环境中，判断分布式寻址算法好坏的原则：
平衡性（Balance） 单调性（Monotonicity） 分散性（Spread） 负载（Load） Hash(Object)%N 集群N台机器，根据N取模，路由到对应的机器，但是缺点在于，对于机器的添加删除，已经缓存的数据都失效、严重违反单调性， 大量的缓存重建
假设0-3个节点、20个数据: 进行取模后分布: 扩容后: 当前只有4个数据能命中。命中率 4/20 = 20% ,命中率底下，并且有大量缓存需要重建
一致性Hash ( DHT ) 公共哈希函数和哈希环 Hash算法设计: 采取取模方式，按常用的 Hash 算法将对应的 Key 哈希到一个具有 2^32 次方的桶空间中，即 0 ~ (2^32)-1 的数字空间。想想一下，将数字首位相连，组成一个闭合的环形。 对象(Object)映射到哈希环 把对象映射到 0-2^32-1 空间里，假设有4个对象 object1-4 ，映射进hash环状 缓存(Cache)映射到哈希环 下面将 Cache 映射进 Hash 空间，假设现在有三个cache：
基本思想就是 Object 和 Cache 都映射到同一 Hash 数值空间中，并且使用相同的 Hash算法，可以使用 Cache 的 IP地址或者其他因子）</description></item><item><title>数据结构与算法 01 优先队列</title><link>https://pinkhello.cc/posts/00-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-01-%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/</link><pubDate>Sat, 09 Feb 2019 10:00:00 +0800</pubDate><guid>https://pinkhello.cc/posts/00-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-01-%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/</guid><description>为什么需要优先队列 队列是一种先进先出的数据结构，所有元素优先级一样，完全遵守先进先出的规则。但是往往现实情况下，这种公平需要被打破。它是一个动态变化的过程，可能有一些需要优先，一些需要降低优先级。且这些数据是一个动态变化的过程，所以需要维系这个优先级队列。
优先队列的实现方式 数组实现 链表</description></item><item><title>算法 Bitmap</title><link>https://pinkhello.cc/posts/00-%E7%AE%97%E6%B3%95-bitmap/</link><pubDate>Sat, 09 Feb 2019 10:00:00 +0800</pubDate><guid>https://pinkhello.cc/posts/00-%E7%AE%97%E6%B3%95-bitmap/</guid><description>bitmap 原理 bitmap字面为位图映射, 原理是使用一个 bit 标记某个元素对应的 value，而 key 即该元素。因为只有一个 bit 来存储一个数据, 因而可以大大的节省空间。
数值映射: 假如对 0-31 个内的3个元素（10, 17, 28）进行排序,可以采用 BitMap 方法, 如下图, 对应的包含的位置将对应的值从 0 变更为 1 假如需要进行排序和检索，只需要依次遍历这个数据结构，碰到 1 的情况，数据存在
字符串映射: 字符串也可映射，只不过需要经过一个Hash步骤,通过映射关系可以判断字符串是否存在。但是因为 Hash是将不确定长度的值变更为确定大小的值,存在Hash冲突性，所以一般要最大化的判断一个字符串是否真的存在，可以将这个字符串经过不同的Hash函数映射不同的位置。
bitmap 的 建立、查找、添加、删除、判断 原理 建立 Bitmap 的创建可以使用 byte 数组， 1 byte = 8 bit (也可使用 int 数组, 1 int = 32 bit, long 数组, 1 long = 64 bit) 也就是说到最后的数据的大小建立只需要创建 数组长度为 int[ 1 + N/32 ] byte[ 1 + N/8 ] long[ 1 + N/64 ] 即可存储，N表示要存储的最大的值。</description></item></channel></rss>